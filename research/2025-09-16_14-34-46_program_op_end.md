---
date: 2025-09-16T14:34:46Z
researcher: Codex
git_commit: ca07cf6d0ee8e19a59e2111a9b06e27bc1d54462
branch: main
repository: nandseqgen_v2
topic: "PROGRAM suspend/resume OP_END scheduling"
tags: [research, codebase, scheduler, event-queue, suspend-resume, addrman]
status: complete
last_updated: 2025-09-16
last_updated_by: Codex
last_updated_note: "AddressManager apply_pgm invocation frequency analysis"
---

# 연구: PROGRAM suspend/resume OP_END scheduling

**Date**: 2025-09-16T14:34:46Z  
**Researcher**: Codex  
**Git Commit**: ca07cf6d0ee8e19a59e2111a9b06e27bc1d54462  
**Branch**: main  
**Repository**: nandseqgen_v2

## 연구 질문
PROGRAM 이 스케쥴 된 후 CORE_BUSY state 에서 SUSPEND→RESUME 을 반복하는 조건에서 PROGRAM 이 반복적으로 스케쥴 될 때 OP_END event_hook 이 언제, 몇 번 큐잉되는가?

## 요약
- Scheduler 는 각 예약된 PROGRAM 세그먼트마다 `_emit_op_events` 를 호출해 `end_us` 시점에 한 번의 OP_END 이벤트를 큐잉한다.  
- SUSPEND 이후 RESUME 이 들어오면 남은 CORE_BUSY 시간을 `_build_core_busy_stub` 으로 새로운 PROGRAM 세그먼트로 만들고, 해당 세그먼트도 OP_END 를 추가로 큐잉한다.  
- 따라서 한 PROGRAM 이 내부적으로 n 번 RESUME 체인을 거치면 총 n+1 개의 PROGRAM OP_END 이벤트가 각 세그먼트의 종료 시각에 선형적으로 예약된다.  
- 이벤트 큐는 동일 타임스탬프에서 OP_END → PHASE_HOOK → QUEUE_REFILL 순으로 처리해 자원 해제를 선행시킨다.
- 각 OP_END 이벤트는 `_am_apply_on_end` 를 통해 AddressManager 의 `apply_pgm` 을 호출하므로, 동일 PROGRAM 에 대한 stub 이 여러 번 만들어지면 `apply_pgm` 도 세그먼트 수만큼 실행된다.  

## 상세 발견

### EventQueue 및 후크 실행 순서
- `Scheduler.tick` 은 시간 슬라이스마다 큐에서 꺼낸 배치에 대해 OP_END → PHASE_HOOK → QUEUE_REFILL 순으로 처리한다. 덕분에 PROGRAM 종료 후 자원/주소 동기화가 후속 프로포절 보다 앞선다. (`scheduler.py:147`)
- `OP_END` 처리는 `_handle_op_end` 를 호출하며, 이 시점에 ResourceManager 가 latch 해제·주소 상태 동기화를 수행한다. (`scheduler.py:200`, `scheduler.py:210`)

### PROGRAM 세그먼트마다 OP_END 큐잉
- `_emit_op_events` 는 예약된 레코드의 시작/종료 시각을 읽어 OP_START/OP_END 이벤트를 모두 큐에 넣는다. PROGRAM 여부와 무관하게 항상 수행된다. (`scheduler.py:673`)
- PROGRAM 세그먼트가 state timeline 을 수정하지 않는 설정이어도, OP_END 이벤트 자체는 그대로 발행된다. (`scheduler.py:684`)

### Suspend→Resume 체인 동작
- RESUME 커밋 시 ResourceManager 의 축적된 `remaining_us` 를 읽어 `_build_core_busy_stub` 로 CORE_BUSY 전용 프로그램을 만든다. (`scheduler.py:388`, `scheduler.py:400`, `scheduler.py:518`)
- stub 예약이 성공하면 `_emit_op_events` 가 다시 호출되어 남은 CORE_BUSY 구간 종료 시각에 또 하나의 OP_END 가 큐잉된다. (`scheduler.py:620`)
- SUSPEND 과정에서 `move_to_suspended_axis` 가 잔여 CORE_BUSY 시간을 계산해 저장하며, 이 값이 stub 생성에 사용된다. (`resourcemgr.py:1082`, `resourcemgr.py:1088`)

### 시뮬레이션 관찰
- 출력된 타임라인에는 각 사용자 PROGRAM 마다 기본 세그먼트와 `RESUME_CHAIN` 세그먼트가 한 쌍으로 존재하며, 각각의 `end` 시각(예: 14400.0 μs, 17600.0 μs)이 OP_END 예약 시각에 해당한다. (`out/operation_timeline_250916_0000001.csv:4`, `out/operation_timeline_250916_0000001.csv:7`)
- 동일 패턴이 후속 PROGRAM 에서도 반복되며, `source=RESUME_CHAIN` 행이 늘어날수록 OP_END 이벤트 수가 증가한다. (`out/operation_timeline_250916_0000001.csv:60`, `out/operation_timeline_250916_0000001.csv:63`)

## 코드 참조
- `scheduler.py:147` – 같은 타임슬라이스에서 OP_END 가 최우선으로 실행되는 루프
- `scheduler.py:673` – `_emit_op_events` 가 OP_START/OP_END 를 큐잉하는 위치
- `scheduler.py:400` – `_build_core_busy_stub` 로 남은 CORE_BUSY 를 PROGRAM 세그먼트로 재구성
- `scheduler.py:518` – RESUME 직후 체인 작업을 준비하는 로직
- `scheduler.py:620` – stub 커밋 후 `_emit_op_events` 를 재호출하여 추가 OP_END 예약
- `resourcemgr.py:1082` – SUSPEND 시 남은 실행 시간을 계산해 meta.remaining_us 로 보존
- `scheduler.py:239` – 각 OP_END 이벤트마다 `_am_apply_on_end` 호출
- `scheduler.py:258` – PROGRAM/ERASE 계열의 OP_END 에서 `apply_pgm` / `apply_erase` 실행 경로
- `addrman.py:607` – `apply_pgm` 이 호출될 때 각 블록의 프로그램 페이지 수를 증가

## 아키텍처 인사이트
- 이벤트 우선순위는 OP 종료 후 즉시 자원/주소 정리를 보장하며, 후속 프로포절이 동일 타임스탬프에서 실행되어도 안정적인 선후 관계를 유지한다.
- Suspend/Resume 체인은 RM 의 remaining_us 측정과 Scheduler 의 stub 재예약으로 분리 구현되어, PROGRAM 이 여러 번 중단되어도 OP_END 이벤트 수가 정확히 세그먼트 수와 일치한다.

## 역사적 맥락
- 현 시점 저장소에는 관련 `thoughts/` 메모가 존재하지 않는다.

## 관련 연구
- `research/2025-09-16_23-13-07_program_suspend_resume_sampling.md` – suspend/resume 샘플링에 대한 이전 분석

## 미해결 질문
- 동일 PROGRAM 에서 두 번 이상 연속 Suspend 가 발생할 때 stub 이 다시 분할되는지 확인할 리플레이가 필요하다.
- 체인 stub 예약 실패 시 OP_END 이벤트 불일치가 없는지 추가 검증이 필요하다.

## 후속 연구 2025-09-16T14:47:51Z
- **질문**: OP_END event_hook 이 여러 번 큐잉될 때 AddressManager.apply_pgm 도 그만큼 호출되는가?
- `_handle_op_end` 는 모든 OP_END 이벤트에서 `_am_apply_on_end` 를 호출하며, PROGRAM 계열(base 에 `PROGRAM` 문자열 포함, SUSPEND/RESUME 제외) 은 `apply_pgm` 대상이다. (`scheduler.py:239`, `scheduler.py:258`)
- `apply_pgm` 은 전달된 타깃 블록을 집계해 페이지 카운터를 증가시키므로, 동일 PROGRAM 이 여러 세그먼트로 나뉘면 세그먼트마다 프로그램 페이지를 누적 갱신한다. (`addrman.py:607`)
- suspend/resume 체인이 만들어낸 stub 역시 `base` 가 `PROGRAM_SLC` 로 유지되기 때문에 `_emit_op_events` 가 큐잉한 OP_END 들이 모두 위 경로를 따라간다. 이를 `source=RESUME_CHAIN` 세그먼트가 반복되는 시퀀스에서 확인했다. (`out/operation_timeline_250916_0000001.csv:7`, `out/operation_timeline_250916_0000001.csv:63`)
- 결과적으로 OP_END 가 n+1 번 큐잉되는 시나리오에서는 AddressManager.apply_pgm 도 동일 횟수만큼 실행되어 블록의 programmed-page 상태를 세그먼트마다 업데이트한다.
